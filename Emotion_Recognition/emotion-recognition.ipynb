{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T01:31:14.165649Z",
     "iopub.status.busy": "2025-04-06T01:31:14.165260Z",
     "iopub.status.idle": "2025-04-06T01:32:11.542752Z",
     "shell.execute_reply": "2025-04-06T01:32:11.542049Z",
     "shell.execute_reply.started": "2025-04-06T01:31:14.165619Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "labels = {\n",
    "    0: \"Angry\",\n",
    "    1: \"Disgust\",\n",
    "    2: \"Fear\",\n",
    "    3: \"Happy\",\n",
    "    4: \"Neutral\",\n",
    "    5: \"Sad\",\n",
    "    6: \"Surprise\",\n",
    "    \n",
    "}\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)  # RGB 정규화\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('/kaggle/input/rafdataset/RAF dataset/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder('/kaggle/input/rafdataset/RAF dataset/test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T01:32:30.603694Z",
     "iopub.status.busy": "2025-04-06T01:32:30.603284Z",
     "iopub.status.idle": "2025-04-06T01:32:33.863182Z",
     "shell.execute_reply": "2025-04-06T01:32:33.862278Z",
     "shell.execute_reply.started": "2025-04-06T01:32:30.603670Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "얼굴 저장 완료: 2424x224.jpg\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "from PIL import Image, ImageEnhance, ImageStat\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# 얼굴 탐지기 초기화\n",
    "mtcnn = MTCNN(keep_all=False, device='cpu')  # 단일 얼굴만\n",
    "\n",
    "def auto_brightness(image, target_mean=250):\n",
    "    \"\"\"\n",
    "    현재 이미지의 밝기 평균을 측정해서,\n",
    "    target_mean(예: 130)에 맞게 밝기 비율을 조정해주는 함수.\n",
    "    \"\"\"\n",
    "    stat = ImageStat.Stat(image)\n",
    "    mean = stat.mean[0]  # 흑백 이미지일 때는 채널이 1개\n",
    "\n",
    "    # 밝기 보정 비율 계산\n",
    "    brightness_factor = target_mean / (mean + 1e-5)\n",
    "\n",
    "    # 너무 과한 보정은 방지 (안정화 범위 지정)\n",
    "    brightness_factor = max(0.7, brightness_factor)\n",
    "\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    return enhancer.enhance(brightness_factor)\n",
    "\n",
    "\n",
    "image_path = 'Example.jpg' # 확인할 이미지\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "image = auto_brightness(image, target_mean=250)\n",
    "\n",
    "\n",
    "# 얼굴 crop\n",
    "face = mtcnn(image)  # 결과: torch.Tensor [3, H, W]\n",
    "\n",
    "if face is not None:\n",
    "    # ⬇️ 전처리: Grayscale + Resize(48x48)\n",
    "    transform = transforms.Compose([\n",
    "        # transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((224, 224))\n",
    "    ])\n",
    "\n",
    "    # 이미지 값 스케일링\n",
    "    face = (face * 255).clamp(0, 255).byte()\n",
    "\n",
    "    # Tensor → PIL 이미지로 변환 후 전처리\n",
    "    face_pil = transforms.ToPILImage()(face)\n",
    "    face_gray_resized = transform(face_pil)\n",
    "\n",
    "    # 저장\n",
    "    face_gray_resized.save(\"224x224.jpg\")\n",
    "    print(\"얼굴 저장 완료: 2424x224.jpg\")\n",
    "\n",
    "else:\n",
    "    print(\"얼굴을 찾을 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 감정 예측 결과: Neutral (99.43%)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from facenet_pytorch import MTCNN\n",
    "from model import EmotionSwin  # Swin 모델 정의\n",
    "\n",
    "# 감정 라벨 정의\n",
    "emotion_labels = {\n",
    "    0: \"Angry\", 1: \"Disgust\", 2: \"Fear\", 3: \"Happy\",\n",
    "    4: \"Neutral\", 5: \"Sad\", 6: \"Surprise\",\n",
    "}\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델 로딩\n",
    "model = EmotionSwin(num_classes=7).to(device)\n",
    "model.load_state_dict(torch.load('emotion_swin_last.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 이미지 경로 (48x48 grayscale 이미지)\n",
    "image_path = '224x224.jpg'\n",
    "\n",
    "# 🔄 전처리: 1채널 → 3채널 복제 → Resize → Tensor → Normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),         # 흑백 → RGB 채널 복제\n",
    "    transforms.Resize((224, 224)),                       # Swin 입력 크기 맞춤\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)      # [-1, 1] 범위 정규화\n",
    "])\n",
    "\n",
    "# 이미지 불러오기 & 전처리\n",
    "image = Image.open(image_path).convert('L')\n",
    "image = transform(image).unsqueeze(0).to(device)  # [1, 3, 224, 224]\n",
    "\n",
    "# 예측\n",
    "with torch.no_grad():\n",
    "    outputs = model(image)\n",
    "    probs = F.softmax(outputs, dim=1)\n",
    "    predicted = torch.argmax(probs, dim=1).item()\n",
    "    confidence = probs[0][predicted].item()\n",
    "\n",
    "# 출력\n",
    "print(f\"🧠 감정 예측 결과: {emotion_labels[predicted]} ({confidence * 100:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7053023,
     "sourceId": 11281196,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
